{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction Background This tool was built by David Guetta to educate and democratize predictive analytics. This tool makes the algorithms that are the foundation to artificial intelligence accessible to anyone for free. The most advanced AI algorithms are built using artificial neural network and have the strongest predictive power, but they require teams of PhDs to design and maintain. The algorithms in this tool provide ~95% of the predictive power of a neural network with ~10% of the work. Please share your feedback with us at ideas@xlkitlearn.com . This excel add-in makes it easy to run causal and predictive analytics like linear/logistic regressions, boosted decision trees, random forests and text analytics using tools like K-fold cross validation, lasso penalties, TF-IDF weights and Latent Dirichlet Allocation. A working understanding of all of these approaches and tools is assumed, but links are included for reference. The general steps to using this tool are: Select data Specify model and parameters Evaluate outputs Use Cases A major difficulty of predictive analytics is understanding the use cases; this tool can be used to: Health Anticipate a cardiac arrest using wearable device data or help a Radiologist review more X-rays with greater accuracy. Banking Better anticipate a borrower's chances of defaulting on a loan or paying off a credit card with a combination of public and underwriting information. Environment Predict the amount of carbon dioxide that a farm has removed from the atmosphere using operation data such as crops planted, irrigation, amount of fertilizer. Retail Let shoppers try on clothes, shoes and furniture with just a picture. Sports Chose the optimal play based on the opponent's historic play calling and field position. Logistics Design the optimal route of delivery based on inventory and customer local. Marketing Autonomously review customer feedback to identify positive, negative and even fake reviews.","title":"Introduction"},{"location":"#introduction","text":"","title":"Introduction"},{"location":"#background","text":"This tool was built by David Guetta to educate and democratize predictive analytics. This tool makes the algorithms that are the foundation to artificial intelligence accessible to anyone for free. The most advanced AI algorithms are built using artificial neural network and have the strongest predictive power, but they require teams of PhDs to design and maintain. The algorithms in this tool provide ~95% of the predictive power of a neural network with ~10% of the work. Please share your feedback with us at ideas@xlkitlearn.com . This excel add-in makes it easy to run causal and predictive analytics like linear/logistic regressions, boosted decision trees, random forests and text analytics using tools like K-fold cross validation, lasso penalties, TF-IDF weights and Latent Dirichlet Allocation. A working understanding of all of these approaches and tools is assumed, but links are included for reference. The general steps to using this tool are: Select data Specify model and parameters Evaluate outputs","title":"Background"},{"location":"#use-cases","text":"A major difficulty of predictive analytics is understanding the use cases; this tool can be used to:","title":"Use Cases"},{"location":"#health","text":"Anticipate a cardiac arrest using wearable device data or help a Radiologist review more X-rays with greater accuracy.","title":"Health"},{"location":"#banking","text":"Better anticipate a borrower's chances of defaulting on a loan or paying off a credit card with a combination of public and underwriting information.","title":"Banking"},{"location":"#environment","text":"Predict the amount of carbon dioxide that a farm has removed from the atmosphere using operation data such as crops planted, irrigation, amount of fertilizer.","title":"Environment"},{"location":"#retail","text":"Let shoppers try on clothes, shoes and furniture with just a picture.","title":"Retail"},{"location":"#sports","text":"Chose the optimal play based on the opponent's historic play calling and field position.","title":"Sports"},{"location":"#logistics","text":"Design the optimal route of delivery based on inventory and customer local.","title":"Logistics"},{"location":"#marketing","text":"Autonomously review customer feedback to identify positive, negative and even fake reviews.","title":"Marketing"},{"location":"intro/","text":"Predictive Analytics Getting started While this is a Python-based add-in, no Python knowledge is needed nor are any downloads besides the XLKit Learn excel file. An email needs to be entered before running any analyses. Email addresses are used to track bugs. Neither email nor analyses will be shared with any outside party. The Edit Settings button allows the user to design analysis like selecting the data, specifying the model, determining the formulas and training criteria. Every time the model is run, the outputs are added as a new tab. Advanced options Windows users have two advanced options below the setting to give the user more control over early termination and processing speed. Mac users have _ _ If the early termination option is selected, a black Python console will pop up. Close the console to stop the analysis. Selecting data If the data can fit in an excel sheet, add the data as a new tab. \"Click to Select\" the range of independent and dependent data including column headers. Column headers should not include spaces. Always add data to the XLKitLearn; don't move the add-in tab to another workbook. When working with very large datasets, save the data as a csv in the same folder as XLKitLearn, and enter the data file name including .csv to select the data. Specifying a Predictive Model XLKitLearn predictive models comprise two main ingredients: The predictive model to be used, and any parameters required to fit this model. The variable that needs to be predicted (the dependent variable) as well as the variables that should be used to predict it (the independent variables). The model can be selected among models available in the Model dropdown, and its parameters can be specified in the Parameter(s) box below. To specify the dependent and independent variables, XLKitLearn leverages the patsy library to allow the specification of these variables as a Patsy formula (similar but not identical to R -style formulas). It also adds a number of features above and beyond those available in Patsy. The basic structure of each formula is as follows: [Dependent Variable] ~ [Independent Variable 1] + [Independent Var. 2] + ... Formulas can be typed directly into the formula box of the add-in settings, or using the formula editor . Each variable should be referred to by the column headers in the first row of the training data . Supported predictive models The following predictive models can be chosen from the dropdown. Linear and logistic regression : If this option is selected, XLKitLearn will automatically determine whether a continuous linear regression model or a binary logistic regression model should be used. If the dependent variable in the model contains 0s or 1s only ( or if the dependent variable is a logical statement ), a logistic regression model will be used. Otherwise, a linear regression model will be used. Note that XLKitLearn does not support classification models with more than two possible outcomes. XLKitLearn makes one unique parameter available for these models - the Lasso penalty . This parameter should either be specified as a number indicating the weight of the Lasso penalty or can be set to BS to perform best subset selection. Compare multiple lasso penalties by separating entries with an & . Decision tree : If this option is selected, XLKitLearn will fit a simple decision tree using CART. Tree depth is the only unique parameter available for decision trees. Multiple depths can also be compared by separating multiple entries with an & . Boosted decision tree: If this option is selected, XLKitLearn will fit a boosted decision tree based on the given Tree depth , Max trees and Learning rate . Different tree depths can be compared by using an & . Only the tree depth should be compared because XLKitLearn will automatically generate trees based on the max number of trees. Random forest: If this option is selected, XLKitLearn will fit a random forest based on Tree depth and the Number of trees which can be compared with an & . The Formula Editor XLKitLearn's formula editor can be accessed by clicking on the three dots to the right of the formula box in the add-in settings. The formula editor lists all the headers in the training data on the left, and provides a larger area in which to enter a formula on the right. When data from an external file (rather than another sheet in the same Excel workbook) is used, Mac security settings do not allow XLKitLearn to open the file and read the headers. Thus, the formula editor will not work when external data is used on a Mac computer. The formula editor also supports auto-complete for quicker formula entry. As variable names are typed in the formula entry box, the list on the left is filtered down to variables that begin with those letters, and the first such variable is automatically suggested. Pressing the Tab key will complete the name of that variable: As in other parts of the add-in, a red input box indicates an error in the formula; the specific error will be displayed in the area at the bottom of the formula editor. Advanced XLKitLearn Formulas The following advanced features are available: Categorical: Variables that have numerical values can be changed into categorical variables by using the following structure in the formula editor C(variable_1) + variable_2.... Any variable with text in it is automatically converted into a categorical variable with the base category dropped. Dot formulas: Include all variables in the model by using the formula y~. in the formula editor Standardization: Standardize each variable by using the following structure in the formula editor standard(variable_1) + standard(variable_2).... Python formulas @guetta I think I missed this one?? Removing the intercept: The intercept can be removed in the formula editor by adding a -1 after the formula Parameter Tuning Specifying the number of folds in the settings will tell the add-in to run a [k-fold cross validation](https://en.wikipedia.org/wiki/Cross-validation_(statistics) with the given number of folds. The training and test data will be randomly sorted into folds based upon the Randomization Seed then all regressions will be automatically run. The model with the highest average out-of-sample score for the training data will used on the evaluation dataset if an evaluation dataset is specified. The Randomization Seed determines the randomization method and can enable two users to generate the same random list. Enter a random list of numbers once the model is finished to truly randomly sort the data. Two or more models can be compared using an & to separate each model in the formula editor . Specifying an evaluation set The \"No evaluation set\" option is selected by default. Reserve data for evaluation by either specifying the proportion of data to be set aside or by selecting a specific evaluation data set range the same way training data is selected. Be careful not to generate an evaluation output dataset that is too big for excel or it might crash. Making predictions on new data Use XLKitLearn to make predictions on new input data using by adding data to the Make predictions for new data section. The predicted outcome will be added to the output. Understanding the Predictive Add-in Output The model output is dynamic based upon the model and dataset. Depending on model type and parameters not all of the following sections will be returned. The output will be separated into: Parameter tuning: A table summarizes the results of the K-Fold Cross-Validation. Each row corresponds to the model the user inputted and shows the In-sample score, Out-of-sample score, Out-of-sample SE, Formula, Lasso penalty and the number of Nonzero coefficients. Below the summary table are two charts to visually compare the models. The first chart shows the out-of-sample score and out-of-sample score SE by the row number / model input. The second chart also shows the out-of-sample score and out-of-sample score SE by the number of non-zero coefficients. Model: The model and lasso penalty is shown along with the in-sample score at the top of the model table. If single model is run, that model is used, if multiple models were compared, the model that returned the highest average out-of-sample score on the training set is returned. The model table will list each variable and the associated coefficient. When a single linear regression is run (is this correct @guetta?) the t-stat, 97.5% confidence interval, p-value and stars indicating levels of statistical significance are also listed. Model Evaluation: Lists every predicted and true outcome for the entire evaluation dataset. The AUC cure and the out-of-sample score for the evaluation set is generated when a evaluation set is specified. Very large datasets can generate evaluation datasets that are too big for excel, so be mindful of how large your evaluation dataset when deciding to include the evaluation Model Prediction: The predicted outcomes for each input True outcome will not be listed because perditions are being made on inputs that don't have outcomes. Equivalent Python code: The Python code that was used to run the analysis with descriptions for each section of code. Technical Details: The input settings that we're used to run the analysis. This can be copied and pasted directly into the \"Settings\" on the Add-in tab to run the exact same analysis again. The add-in version and the time for each step of the analysis are also noted.","title":"Predictive Analytics"},{"location":"intro/#predictive-analytics","text":"","title":"Predictive Analytics"},{"location":"intro/#getting-started","text":"While this is a Python-based add-in, no Python knowledge is needed nor are any downloads besides the XLKit Learn excel file. An email needs to be entered before running any analyses. Email addresses are used to track bugs. Neither email nor analyses will be shared with any outside party. The Edit Settings button allows the user to design analysis like selecting the data, specifying the model, determining the formulas and training criteria. Every time the model is run, the outputs are added as a new tab.","title":"Getting started"},{"location":"intro/#advanced-options","text":"Windows users have two advanced options below the setting to give the user more control over early termination and processing speed. Mac users have _ _ If the early termination option is selected, a black Python console will pop up. Close the console to stop the analysis.","title":"Advanced options"},{"location":"intro/#selecting-data","text":"If the data can fit in an excel sheet, add the data as a new tab. \"Click to Select\" the range of independent and dependent data including column headers. Column headers should not include spaces. Always add data to the XLKitLearn; don't move the add-in tab to another workbook. When working with very large datasets, save the data as a csv in the same folder as XLKitLearn, and enter the data file name including .csv to select the data.","title":"Selecting data"},{"location":"intro/#specifying-a-predictive-model","text":"XLKitLearn predictive models comprise two main ingredients: The predictive model to be used, and any parameters required to fit this model. The variable that needs to be predicted (the dependent variable) as well as the variables that should be used to predict it (the independent variables). The model can be selected among models available in the Model dropdown, and its parameters can be specified in the Parameter(s) box below. To specify the dependent and independent variables, XLKitLearn leverages the patsy library to allow the specification of these variables as a Patsy formula (similar but not identical to R -style formulas). It also adds a number of features above and beyond those available in Patsy. The basic structure of each formula is as follows: [Dependent Variable] ~ [Independent Variable 1] + [Independent Var. 2] + ... Formulas can be typed directly into the formula box of the add-in settings, or using the formula editor . Each variable should be referred to by the column headers in the first row of the training data .","title":"Specifying a Predictive Model"},{"location":"intro/#supported-predictive-models","text":"The following predictive models can be chosen from the dropdown. Linear and logistic regression : If this option is selected, XLKitLearn will automatically determine whether a continuous linear regression model or a binary logistic regression model should be used. If the dependent variable in the model contains 0s or 1s only ( or if the dependent variable is a logical statement ), a logistic regression model will be used. Otherwise, a linear regression model will be used. Note that XLKitLearn does not support classification models with more than two possible outcomes. XLKitLearn makes one unique parameter available for these models - the Lasso penalty . This parameter should either be specified as a number indicating the weight of the Lasso penalty or can be set to BS to perform best subset selection. Compare multiple lasso penalties by separating entries with an & . Decision tree : If this option is selected, XLKitLearn will fit a simple decision tree using CART. Tree depth is the only unique parameter available for decision trees. Multiple depths can also be compared by separating multiple entries with an & . Boosted decision tree: If this option is selected, XLKitLearn will fit a boosted decision tree based on the given Tree depth , Max trees and Learning rate . Different tree depths can be compared by using an & . Only the tree depth should be compared because XLKitLearn will automatically generate trees based on the max number of trees. Random forest: If this option is selected, XLKitLearn will fit a random forest based on Tree depth and the Number of trees which can be compared with an & .","title":"Supported predictive models"},{"location":"intro/#the-formula-editor","text":"XLKitLearn's formula editor can be accessed by clicking on the three dots to the right of the formula box in the add-in settings. The formula editor lists all the headers in the training data on the left, and provides a larger area in which to enter a formula on the right. When data from an external file (rather than another sheet in the same Excel workbook) is used, Mac security settings do not allow XLKitLearn to open the file and read the headers. Thus, the formula editor will not work when external data is used on a Mac computer. The formula editor also supports auto-complete for quicker formula entry. As variable names are typed in the formula entry box, the list on the left is filtered down to variables that begin with those letters, and the first such variable is automatically suggested. Pressing the Tab key will complete the name of that variable: As in other parts of the add-in, a red input box indicates an error in the formula; the specific error will be displayed in the area at the bottom of the formula editor.","title":"The Formula Editor"},{"location":"intro/#advanced-xlkitlearn-formulas","text":"The following advanced features are available: Categorical: Variables that have numerical values can be changed into categorical variables by using the following structure in the formula editor C(variable_1) + variable_2.... Any variable with text in it is automatically converted into a categorical variable with the base category dropped. Dot formulas: Include all variables in the model by using the formula y~. in the formula editor Standardization: Standardize each variable by using the following structure in the formula editor standard(variable_1) + standard(variable_2).... Python formulas @guetta I think I missed this one?? Removing the intercept: The intercept can be removed in the formula editor by adding a -1 after the formula","title":"Advanced XLKitLearn Formulas"},{"location":"intro/#parameter-tuning","text":"Specifying the number of folds in the settings will tell the add-in to run a [k-fold cross validation](https://en.wikipedia.org/wiki/Cross-validation_(statistics) with the given number of folds. The training and test data will be randomly sorted into folds based upon the Randomization Seed then all regressions will be automatically run. The model with the highest average out-of-sample score for the training data will used on the evaluation dataset if an evaluation dataset is specified. The Randomization Seed determines the randomization method and can enable two users to generate the same random list. Enter a random list of numbers once the model is finished to truly randomly sort the data. Two or more models can be compared using an & to separate each model in the formula editor .","title":"Parameter Tuning"},{"location":"intro/#specifying-an-evaluation-set","text":"The \"No evaluation set\" option is selected by default. Reserve data for evaluation by either specifying the proportion of data to be set aside or by selecting a specific evaluation data set range the same way training data is selected. Be careful not to generate an evaluation output dataset that is too big for excel or it might crash.","title":"Specifying an evaluation set"},{"location":"intro/#making-predictions-on-new-data","text":"Use XLKitLearn to make predictions on new input data using by adding data to the Make predictions for new data section. The predicted outcome will be added to the output.","title":"Making predictions on new data"},{"location":"intro/#understanding-the-predictive-add-in-output","text":"The model output is dynamic based upon the model and dataset. Depending on model type and parameters not all of the following sections will be returned. The output will be separated into: Parameter tuning: A table summarizes the results of the K-Fold Cross-Validation. Each row corresponds to the model the user inputted and shows the In-sample score, Out-of-sample score, Out-of-sample SE, Formula, Lasso penalty and the number of Nonzero coefficients. Below the summary table are two charts to visually compare the models. The first chart shows the out-of-sample score and out-of-sample score SE by the row number / model input. The second chart also shows the out-of-sample score and out-of-sample score SE by the number of non-zero coefficients. Model: The model and lasso penalty is shown along with the in-sample score at the top of the model table. If single model is run, that model is used, if multiple models were compared, the model that returned the highest average out-of-sample score on the training set is returned. The model table will list each variable and the associated coefficient. When a single linear regression is run (is this correct @guetta?) the t-stat, 97.5% confidence interval, p-value and stars indicating levels of statistical significance are also listed. Model Evaluation: Lists every predicted and true outcome for the entire evaluation dataset. The AUC cure and the out-of-sample score for the evaluation set is generated when a evaluation set is specified. Very large datasets can generate evaluation datasets that are too big for excel, so be mindful of how large your evaluation dataset when deciding to include the evaluation Model Prediction: The predicted outcomes for each input True outcome will not be listed because perditions are being made on inputs that don't have outcomes. Equivalent Python code: The Python code that was used to run the analysis with descriptions for each section of code. Technical Details: The input settings that we're used to run the analysis. This can be copied and pasted directly into the \"Settings\" on the Add-in tab to run the exact same analysis again. The add-in version and the time for each step of the analysis are also noted.","title":"Understanding the Predictive Add-in Output"},{"location":"text/","text":"Text Analytics","title":"Text Analytics"},{"location":"text/#text-analytics","text":"","title":"Text Analytics"}]}